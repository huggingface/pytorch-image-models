
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Pretained Image Recognition Models">
      
      
      
      
        <link rel="prev" href="../feature_extraction/">
      
      
        <link rel="next" href="../archived_changes/">
      
      <link rel="icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.4.2, mkdocs-material-9.0.2">
    
    
      
        <title>Recent Changes - Pytorch Image Models</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.f56500e0.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.2505c338.min.css">
      
      

    
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="" data-md-color-accent="">
  
    
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#recent-changes" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="Pytorch Image Models" class="md-header__button md-logo" aria-label="Pytorch Image Models" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Pytorch Image Models
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Recent Changes
            
          </span>
        </div>
      </div>
    </div>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/rwightman/pytorch-image-models" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.2.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    rwightman/pytorch-image-models
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="Pytorch Image Models" class="md-nav__button md-logo" aria-label="Pytorch Image Models" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    Pytorch Image Models
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/rwightman/pytorch-image-models" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.2.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    rwightman/pytorch-image-models
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        Getting Started
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../models/" class="md-nav__link">
        Model Summaries
      </a>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3" type="checkbox" id="__nav_3" >
      
      
      
      
        <label class="md-nav__link" for="__nav_3">
          Model Pages
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Model Pages" data-md-level="1">
        <label class="md-nav__title" for="__nav_3">
          <span class="md-nav__icon md-icon"></span>
          Model Pages
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../models/adversarial-inception-v3/" class="md-nav__link">
        Adversarial Inception v3
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../models/advprop/" class="md-nav__link">
        AdvProp (EfficientNet)
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../models/big-transfer/" class="md-nav__link">
        Big Transfer (BiT)
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../models/csp-darknet/" class="md-nav__link">
        CSP-DarkNet
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../models/csp-resnet/" class="md-nav__link">
        CSP-ResNet
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../models/csp-resnext/" class="md-nav__link">
        CSP-ResNeXt
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../models/densenet/" class="md-nav__link">
        DenseNet
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../models/dla/" class="md-nav__link">
        Deep Layer Aggregation
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../models/dpn/" class="md-nav__link">
        Dual Path Network (DPN)
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../models/ecaresnet/" class="md-nav__link">
        ECA-ResNet
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../models/efficientnet-pruned/" class="md-nav__link">
        EfficientNet (Knapsack Pruned)
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../models/efficientnet/" class="md-nav__link">
        EfficientNet
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../models/ensemble-adversarial/" class="md-nav__link">
        Ensemble Adversarial Inception ResNet v2
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../models/ese-vovnet/" class="md-nav__link">
        ESE-VoVNet
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../models/fbnet/" class="md-nav__link">
        FBNet
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../models/gloun-inception-v3/" class="md-nav__link">
        (Gluon) Inception v3
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../models/gloun-resnet/" class="md-nav__link">
        (Gluon) ResNet
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../models/gloun-resnext/" class="md-nav__link">
        (Gluon) ResNeXt
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../models/gloun-senet/" class="md-nav__link">
        (Gluon) SENet
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../models/gloun-seresnext/" class="md-nav__link">
        (Gluon) SE-ResNeXt
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../models/gloun-xception/" class="md-nav__link">
        (Gluon) Xception
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../models/hrnet/" class="md-nav__link">
        HRNet
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../models/ig-resnext/" class="md-nav__link">
        Instagram ResNeXt WSL
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../models/inception-resnet-v2/" class="md-nav__link">
        Inception ResNet v2
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../models/inception-v3/" class="md-nav__link">
        Inception v3
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../models/inception-v4/" class="md-nav__link">
        Inception v4
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../models/legacy-se-resnet/" class="md-nav__link">
        (Legacy) SE-ResNet
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../models/legacy-se-resnext/" class="md-nav__link">
        (Legacy) SE-ResNeXt
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../models/legacy-senet/" class="md-nav__link">
        (Legacy) SENet
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../models/mixnet/" class="md-nav__link">
        MixNet
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../models/mnasnet/" class="md-nav__link">
        MnasNet
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../models/mobilenet-v2/" class="md-nav__link">
        MobileNet v2
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../models/mobilenet-v3/" class="md-nav__link">
        MobileNet v3
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../models/nasnet/" class="md-nav__link">
        NASNet
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../models/noisy-student/" class="md-nav__link">
        Noisy Student (EfficientNet)
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../models/pnasnet/" class="md-nav__link">
        PNASNet
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../models/regnetx/" class="md-nav__link">
        RegNetX
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../models/regnety/" class="md-nav__link">
        RegNetY
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../models/res2net/" class="md-nav__link">
        Res2Net
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../models/res2next/" class="md-nav__link">
        Res2NeXt
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../models/resnest/" class="md-nav__link">
        ResNeSt
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../models/resnet-d/" class="md-nav__link">
        ResNet-D
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../models/resnet/" class="md-nav__link">
        ResNet
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../models/resnext/" class="md-nav__link">
        ResNeXt
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../models/rexnet/" class="md-nav__link">
        RexNet
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../models/se-resnet/" class="md-nav__link">
        SE-ResNet
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../models/selecsls/" class="md-nav__link">
        SelecSLS
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../models/seresnext/" class="md-nav__link">
        SE-ResNeXt
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../models/skresnet/" class="md-nav__link">
        SK-ResNet
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../models/skresnext/" class="md-nav__link">
        SK-ResNeXt
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../models/spnasnet/" class="md-nav__link">
        SPNASNet
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../models/ssl-resnet/" class="md-nav__link">
        SSL ResNet
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../models/ssl-resnext/" class="md-nav__link">
        SSL ResNeXT
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../models/swsl-resnet/" class="md-nav__link">
        SWSL ResNet
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../models/swsl-resnext/" class="md-nav__link">
        SWSL ResNeXt
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../models/tf-efficientnet-condconv/" class="md-nav__link">
        (Tensorflow) EfficientNet CondConv
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../models/tf-efficientnet-lite/" class="md-nav__link">
        (Tensorflow) EfficientNet Lite
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../models/tf-efficientnet/" class="md-nav__link">
        (Tensorflow) EfficientNet
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../models/tf-inception-v3/" class="md-nav__link">
        (Tensorflow) Inception v3
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../models/tf-mixnet/" class="md-nav__link">
        (Tensorflow) MixNet
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../models/tf-mobilenet-v3/" class="md-nav__link">
        (Tensorflow) MobileNet v3
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../models/tresnet/" class="md-nav__link">
        TResNet
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../models/vision-transformer/" class="md-nav__link">
        Vision Transformer (ViT)
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../models/wide-resnet/" class="md-nav__link">
        Wide ResNet
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../models/xception/" class="md-nav__link">
        Xception
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../results/" class="md-nav__link">
        Results
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../scripts/" class="md-nav__link">
        Scripts
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../training_hparam_examples/" class="md-nav__link">
        Training Examples
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../feature_extraction/" class="md-nav__link">
        Feature Extraction
      </a>
    </li>
  

    
      
      
      

  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          Recent Changes
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        Recent Changes
      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#jan-5-2023" class="md-nav__link">
    Jan 5, 2023
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#dec-23-2022" class="md-nav__link">
    Dec 23, 2022 ðŸŽ„â˜ƒ
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#dec-8-2022" class="md-nav__link">
    Dec 8, 2022
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#dec-6-2022" class="md-nav__link">
    Dec 6, 2022
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#dec-5-2022" class="md-nav__link">
    Dec 5, 2022
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#oct-15-2022" class="md-nav__link">
    Oct 15, 2022
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#oct-10-2022" class="md-nav__link">
    Oct 10, 2022
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sept-23-2022" class="md-nav__link">
    Sept 23, 2022
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sept-7-2022" class="md-nav__link">
    Sept 7, 2022
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#aug-29-2022" class="md-nav__link">
    Aug 29, 2022
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#aug-26-2022" class="md-nav__link">
    Aug 26, 2022
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#aug-15-2022" class="md-nav__link">
    Aug 15, 2022
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#aug-5-2022" class="md-nav__link">
    Aug 5, 2022
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#july-28-2022" class="md-nav__link">
    July 28, 2022
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#july-27-2022" class="md-nav__link">
    July 27, 2022
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#july-8-2022" class="md-nav__link">
    July 8, 2022
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#may-13-2022" class="md-nav__link">
    May 13, 2022
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#may-2-2022" class="md-nav__link">
    May 2, 2022
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#april-22-2022" class="md-nav__link">
    April 22, 2022
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#march-23-2022" class="md-nav__link">
    March 23, 2022
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#march-21-2022" class="md-nav__link">
    March 21, 2022
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#feb-2-2022" class="md-nav__link">
    Feb 2, 2022
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#jan-14-2022" class="md-nav__link">
    Jan 14, 2022
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../archived_changes/" class="md-nav__link">
        Archived Changes
      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#jan-5-2023" class="md-nav__link">
    Jan 5, 2023
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#dec-23-2022" class="md-nav__link">
    Dec 23, 2022 ðŸŽ„â˜ƒ
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#dec-8-2022" class="md-nav__link">
    Dec 8, 2022
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#dec-6-2022" class="md-nav__link">
    Dec 6, 2022
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#dec-5-2022" class="md-nav__link">
    Dec 5, 2022
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#oct-15-2022" class="md-nav__link">
    Oct 15, 2022
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#oct-10-2022" class="md-nav__link">
    Oct 10, 2022
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sept-23-2022" class="md-nav__link">
    Sept 23, 2022
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sept-7-2022" class="md-nav__link">
    Sept 7, 2022
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#aug-29-2022" class="md-nav__link">
    Aug 29, 2022
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#aug-26-2022" class="md-nav__link">
    Aug 26, 2022
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#aug-15-2022" class="md-nav__link">
    Aug 15, 2022
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#aug-5-2022" class="md-nav__link">
    Aug 5, 2022
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#july-28-2022" class="md-nav__link">
    July 28, 2022
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#july-27-2022" class="md-nav__link">
    July 27, 2022
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#july-8-2022" class="md-nav__link">
    July 8, 2022
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#may-13-2022" class="md-nav__link">
    May 13, 2022
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#may-2-2022" class="md-nav__link">
    May 2, 2022
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#april-22-2022" class="md-nav__link">
    April 22, 2022
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#march-23-2022" class="md-nav__link">
    March 23, 2022
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#march-21-2022" class="md-nav__link">
    March 21, 2022
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#feb-2-2022" class="md-nav__link">
    Feb 2, 2022
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#jan-14-2022" class="md-nav__link">
    Jan 14, 2022
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
  



<h1 id="recent-changes">Recent Changes</h1>
<h3 id="jan-5-2023">Jan 5, 2023</h3>
<ul>
<li>ConvNeXt-V2 models and weights added to existing <code>convnext.py</code><ul>
<li>Paper: <a href="http://arxiv.org/abs/2301.00808">ConvNeXt V2: Co-designing and Scaling ConvNets with Masked Autoencoders</a></li>
<li>Reference impl: <a href="https://github.com/facebookresearch/ConvNeXt-V2">https://github.com/facebookresearch/ConvNeXt-V2</a> (NOTE: weights currently CC-BY-NC)</li>
</ul>
</li>
</ul>
<h3 id="dec-23-2022">Dec 23, 2022 ðŸŽ„â˜ƒ</h3>
<ul>
<li>Add FlexiViT models and weights from <a href="https://github.com/google-research/big_vision">https://github.com/google-research/big_vision</a> (check out paper at <a href="https://arxiv.org/abs/2212.08013">https://arxiv.org/abs/2212.08013</a>)<ul>
<li>NOTE currently resizing is static on model creation, on-the-fly dynamic / train patch size sampling is a WIP</li>
</ul>
</li>
<li>Many more models updated to multi-weight and downloadable via HF hub now (convnext, efficientnet, mobilenet, vision_transformer*, beit)</li>
<li>More model pretrained tag and adjustments, some model names changed (working on deprecation translations, consider main branch DEV branch right now, use 0.6.x for stable use)</li>
<li>More ImageNet-12k (subset of 22k) pretrain models popping up:<ul>
<li><code>efficientnet_b5.in12k_ft_in1k</code> - 85.9 @ 448x448</li>
<li><code>vit_medium_patch16_gap_384.in12k_ft_in1k</code> - 85.5 @ 384x384</li>
<li><code>vit_medium_patch16_gap_256.in12k_ft_in1k</code> - 84.5 @ 256x256</li>
<li><code>convnext_nano.in12k_ft_in1k</code> - 82.9 @ 288x288</li>
</ul>
</li>
</ul>
<h3 id="dec-8-2022">Dec 8, 2022</h3>
<ul>
<li>Add 'EVA l' to <code>vision_transformer.py</code>, MAE style ViT-L/14 MIM pretrain w/ EVA-CLIP targets, FT on ImageNet-1k (w/ ImageNet-22k intermediate for some)<ul>
<li>original source: <a href="https://github.com/baaivision/EVA">https://github.com/baaivision/EVA</a></li>
</ul>
</li>
</ul>
<table>
<thead>
<tr>
<th align="left">model</th>
<th align="right">top1</th>
<th align="right">param_count</th>
<th align="right">gmac</th>
<th align="right">macts</th>
<th align="left">hub</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left">eva_large_patch14_336.in22k_ft_in22k_in1k</td>
<td align="right">89.2</td>
<td align="right">304.5</td>
<td align="right">191.1</td>
<td align="right">270.2</td>
<td align="left"><a href="https://huggingface.co/BAAI/EVA">link</a></td>
</tr>
<tr>
<td align="left">eva_large_patch14_336.in22k_ft_in1k</td>
<td align="right">88.7</td>
<td align="right">304.5</td>
<td align="right">191.1</td>
<td align="right">270.2</td>
<td align="left"><a href="https://huggingface.co/BAAI/EVA">link</a></td>
</tr>
<tr>
<td align="left">eva_large_patch14_196.in22k_ft_in22k_in1k</td>
<td align="right">88.6</td>
<td align="right">304.1</td>
<td align="right">61.6</td>
<td align="right">63.5</td>
<td align="left"><a href="https://huggingface.co/BAAI/EVA">link</a></td>
</tr>
<tr>
<td align="left">eva_large_patch14_196.in22k_ft_in1k</td>
<td align="right">87.9</td>
<td align="right">304.1</td>
<td align="right">61.6</td>
<td align="right">63.5</td>
<td align="left"><a href="https://huggingface.co/BAAI/EVA">link</a></td>
</tr>
</tbody>
</table>
<h3 id="dec-6-2022">Dec 6, 2022</h3>
<ul>
<li>Add 'EVA g', BEiT style ViT-g/14 model weights w/ both MIM pretrain and CLIP pretrain to <code>beit.py</code>. <ul>
<li>original source: <a href="https://github.com/baaivision/EVA">https://github.com/baaivision/EVA</a></li>
<li>paper: <a href="https://arxiv.org/abs/2211.07636">https://arxiv.org/abs/2211.07636</a></li>
</ul>
</li>
</ul>
<table>
<thead>
<tr>
<th align="left">model</th>
<th align="right">top1</th>
<th align="right">param_count</th>
<th align="right">gmac</th>
<th align="right">macts</th>
<th align="left">hub</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left">eva_giant_patch14_560.m30m_ft_in22k_in1k</td>
<td align="right">89.8</td>
<td align="right">1014.4</td>
<td align="right">1906.8</td>
<td align="right">2577.2</td>
<td align="left"><a href="https://huggingface.co/BAAI/EVA">link</a></td>
</tr>
<tr>
<td align="left">eva_giant_patch14_336.m30m_ft_in22k_in1k</td>
<td align="right">89.6</td>
<td align="right">1013</td>
<td align="right">620.6</td>
<td align="right">550.7</td>
<td align="left"><a href="https://huggingface.co/BAAI/EVA">link</a></td>
</tr>
<tr>
<td align="left">eva_giant_patch14_336.clip_ft_in1k</td>
<td align="right">89.4</td>
<td align="right">1013</td>
<td align="right">620.6</td>
<td align="right">550.7</td>
<td align="left"><a href="https://huggingface.co/BAAI/EVA">link</a></td>
</tr>
<tr>
<td align="left">eva_giant_patch14_224.clip_ft_in1k</td>
<td align="right">89.1</td>
<td align="right">1012.6</td>
<td align="right">267.2</td>
<td align="right">192.6</td>
<td align="left"><a href="https://huggingface.co/BAAI/EVA">link</a></td>
</tr>
</tbody>
</table>
<h3 id="dec-5-2022">Dec 5, 2022</h3>
<ul>
<li>Pre-release (<code>0.8.0dev0</code>) of multi-weight support (<code>model_arch.pretrained_tag</code>). Install with <code>pip install --pre timm</code><ul>
<li>vision_transformer, maxvit, convnext are the first three model impl w/ support</li>
<li>model names are changing with this (previous _21k, etc. fn will merge), still sorting out deprecation handling</li>
<li>bugs are likely, but I need feedback so please try it out</li>
<li>if stability is needed, please use 0.6.x pypi releases or clone from <a href="https://github.com/rwightman/pytorch-image-models/tree/0.6.x">0.6.x branch</a></li>
</ul>
</li>
<li>Support for PyTorch 2.0 compile is added in train/validate/inference/benchmark, use <code>--torchcompile</code> argument</li>
<li>Inference script allows more control over output, select k for top-class index + prob json, csv or parquet output</li>
<li>Add a full set of fine-tuned CLIP image tower weights from both LAION-2B and original OpenAI CLIP models</li>
</ul>
<table>
<thead>
<tr>
<th align="left">model</th>
<th align="right">top1</th>
<th align="right">param_count</th>
<th align="right">gmac</th>
<th align="right">macts</th>
<th align="left">hub</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left">vit_huge_patch14_clip_336.laion2b_ft_in12k_in1k</td>
<td align="right">88.6</td>
<td align="right">632.5</td>
<td align="right">391</td>
<td align="right">407.5</td>
<td align="left"><a href="https://huggingface.co/timm/vit_huge_patch14_clip_336.laion2b_ft_in12k_in1k">link</a></td>
</tr>
<tr>
<td align="left">vit_large_patch14_clip_336.openai_ft_in12k_in1k</td>
<td align="right">88.3</td>
<td align="right">304.5</td>
<td align="right">191.1</td>
<td align="right">270.2</td>
<td align="left"><a href="https://huggingface.co/timm/vit_large_patch14_clip_336.openai_ft_in12k_in1k">link</a></td>
</tr>
<tr>
<td align="left">vit_huge_patch14_clip_224.laion2b_ft_in12k_in1k</td>
<td align="right">88.2</td>
<td align="right">632</td>
<td align="right">167.4</td>
<td align="right">139.4</td>
<td align="left"><a href="https://huggingface.co/timm/vit_huge_patch14_clip_224.laion2b_ft_in12k_in1k">link</a></td>
</tr>
<tr>
<td align="left">vit_large_patch14_clip_336.laion2b_ft_in12k_in1k</td>
<td align="right">88.2</td>
<td align="right">304.5</td>
<td align="right">191.1</td>
<td align="right">270.2</td>
<td align="left"><a href="https://huggingface.co/timm/vit_large_patch14_clip_336.laion2b_ft_in12k_in1k">link</a></td>
</tr>
<tr>
<td align="left">vit_large_patch14_clip_224.openai_ft_in12k_in1k</td>
<td align="right">88.2</td>
<td align="right">304.2</td>
<td align="right">81.1</td>
<td align="right">88.8</td>
<td align="left"><a href="https://huggingface.co/timm/vit_large_patch14_clip_224.openai_ft_in12k_in1k">link</a></td>
</tr>
<tr>
<td align="left">vit_large_patch14_clip_224.laion2b_ft_in12k_in1k</td>
<td align="right">87.9</td>
<td align="right">304.2</td>
<td align="right">81.1</td>
<td align="right">88.8</td>
<td align="left"><a href="https://huggingface.co/timm/vit_large_patch14_clip_224.laion2b_ft_in12k_in1k">link</a></td>
</tr>
<tr>
<td align="left">vit_large_patch14_clip_224.openai_ft_in1k</td>
<td align="right">87.9</td>
<td align="right">304.2</td>
<td align="right">81.1</td>
<td align="right">88.8</td>
<td align="left"><a href="https://huggingface.co/timm/vit_large_patch14_clip_224.openai_ft_in1k">link</a></td>
</tr>
<tr>
<td align="left">vit_large_patch14_clip_336.laion2b_ft_in1k</td>
<td align="right">87.9</td>
<td align="right">304.5</td>
<td align="right">191.1</td>
<td align="right">270.2</td>
<td align="left"><a href="https://huggingface.co/timm/vit_large_patch14_clip_336.laion2b_ft_in1k">link</a></td>
</tr>
<tr>
<td align="left">vit_huge_patch14_clip_224.laion2b_ft_in1k</td>
<td align="right">87.6</td>
<td align="right">632</td>
<td align="right">167.4</td>
<td align="right">139.4</td>
<td align="left"><a href="https://huggingface.co/timm/vit_huge_patch14_clip_224.laion2b_ft_in1k">link</a></td>
</tr>
<tr>
<td align="left">vit_large_patch14_clip_224.laion2b_ft_in1k</td>
<td align="right">87.3</td>
<td align="right">304.2</td>
<td align="right">81.1</td>
<td align="right">88.8</td>
<td align="left"><a href="https://huggingface.co/timm/vit_large_patch14_clip_224.laion2b_ft_in1k">link</a></td>
</tr>
<tr>
<td align="left">vit_base_patch16_clip_384.laion2b_ft_in12k_in1k</td>
<td align="right">87.2</td>
<td align="right">86.9</td>
<td align="right">55.5</td>
<td align="right">101.6</td>
<td align="left"><a href="https://huggingface.co/timm/vit_base_patch16_clip_384.laion2b_ft_in12k_in1k">link</a></td>
</tr>
<tr>
<td align="left">vit_base_patch16_clip_384.openai_ft_in12k_in1k</td>
<td align="right">87</td>
<td align="right">86.9</td>
<td align="right">55.5</td>
<td align="right">101.6</td>
<td align="left"><a href="https://huggingface.co/timm/vit_base_patch16_clip_384.openai_ft_in12k_in1k">link</a></td>
</tr>
<tr>
<td align="left">vit_base_patch16_clip_384.laion2b_ft_in1k</td>
<td align="right">86.6</td>
<td align="right">86.9</td>
<td align="right">55.5</td>
<td align="right">101.6</td>
<td align="left"><a href="https://huggingface.co/timm/vit_base_patch16_clip_384.laion2b_ft_in1k">link</a></td>
</tr>
<tr>
<td align="left">vit_base_patch16_clip_384.openai_ft_in1k</td>
<td align="right">86.2</td>
<td align="right">86.9</td>
<td align="right">55.5</td>
<td align="right">101.6</td>
<td align="left"><a href="https://huggingface.co/timm/vit_base_patch16_clip_384.openai_ft_in1k">link</a></td>
</tr>
<tr>
<td align="left">vit_base_patch16_clip_224.laion2b_ft_in12k_in1k</td>
<td align="right">86.2</td>
<td align="right">86.6</td>
<td align="right">17.6</td>
<td align="right">23.9</td>
<td align="left"><a href="https://huggingface.co/timm/vit_base_patch16_clip_224.laion2b_ft_in12k_in1k">link</a></td>
</tr>
<tr>
<td align="left">vit_base_patch16_clip_224.openai_ft_in12k_in1k</td>
<td align="right">85.9</td>
<td align="right">86.6</td>
<td align="right">17.6</td>
<td align="right">23.9</td>
<td align="left"><a href="https://huggingface.co/timm/vit_base_patch16_clip_224.openai_ft_in12k_in1k">link</a></td>
</tr>
<tr>
<td align="left">vit_base_patch32_clip_448.laion2b_ft_in12k_in1k</td>
<td align="right">85.8</td>
<td align="right">88.3</td>
<td align="right">17.9</td>
<td align="right">23.9</td>
<td align="left"><a href="https://huggingface.co/timm/vit_base_patch32_clip_448.laion2b_ft_in12k_in1k">link</a></td>
</tr>
<tr>
<td align="left">vit_base_patch16_clip_224.laion2b_ft_in1k</td>
<td align="right">85.5</td>
<td align="right">86.6</td>
<td align="right">17.6</td>
<td align="right">23.9</td>
<td align="left"><a href="https://huggingface.co/timm/vit_base_patch16_clip_224.laion2b_ft_in1k">link</a></td>
</tr>
<tr>
<td align="left">vit_base_patch32_clip_384.laion2b_ft_in12k_in1k</td>
<td align="right">85.4</td>
<td align="right">88.3</td>
<td align="right">13.1</td>
<td align="right">16.5</td>
<td align="left"><a href="https://huggingface.co/timm/vit_base_patch32_clip_384.laion2b_ft_in12k_in1k">link</a></td>
</tr>
<tr>
<td align="left">vit_base_patch16_clip_224.openai_ft_in1k</td>
<td align="right">85.3</td>
<td align="right">86.6</td>
<td align="right">17.6</td>
<td align="right">23.9</td>
<td align="left"><a href="https://huggingface.co/timm/vit_base_patch16_clip_224.openai_ft_in1k">link</a></td>
</tr>
<tr>
<td align="left">vit_base_patch32_clip_384.openai_ft_in12k_in1k</td>
<td align="right">85.2</td>
<td align="right">88.3</td>
<td align="right">13.1</td>
<td align="right">16.5</td>
<td align="left"><a href="https://huggingface.co/timm/vit_base_patch32_clip_384.openai_ft_in12k_in1k">link</a></td>
</tr>
<tr>
<td align="left">vit_base_patch32_clip_224.laion2b_ft_in12k_in1k</td>
<td align="right">83.3</td>
<td align="right">88.2</td>
<td align="right">4.4</td>
<td align="right">5</td>
<td align="left"><a href="https://huggingface.co/timm/vit_base_patch32_clip_224.laion2b_ft_in12k_in1k">link</a></td>
</tr>
<tr>
<td align="left">vit_base_patch32_clip_224.laion2b_ft_in1k</td>
<td align="right">82.6</td>
<td align="right">88.2</td>
<td align="right">4.4</td>
<td align="right">5</td>
<td align="left"><a href="https://huggingface.co/timm/vit_base_patch32_clip_224.laion2b_ft_in1k">link</a></td>
</tr>
<tr>
<td align="left">vit_base_patch32_clip_224.openai_ft_in1k</td>
<td align="right">81.9</td>
<td align="right">88.2</td>
<td align="right">4.4</td>
<td align="right">5</td>
<td align="left"><a href="https://huggingface.co/timm/vit_base_patch32_clip_224.openai_ft_in1k">link</a></td>
</tr>
</tbody>
</table>
<ul>
<li>Port of MaxViT Tensorflow Weights from official impl at <a href="https://github.com/google-research/maxvit">https://github.com/google-research/maxvit</a><ul>
<li>There was larger than expected drops for the upscaled 384/512 in21k fine-tune weights, possible detail missing, but the 21k FT did seem sensitive to small preprocessing</li>
</ul>
</li>
</ul>
<table>
<thead>
<tr>
<th align="left">model</th>
<th align="right">top1</th>
<th align="right">param_count</th>
<th align="right">gmac</th>
<th align="right">macts</th>
<th align="left">hub</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left">maxvit_xlarge_tf_512.in21k_ft_in1k</td>
<td align="right">88.5</td>
<td align="right">475.8</td>
<td align="right">534.1</td>
<td align="right">1413.2</td>
<td align="left"><a href="https://huggingface.co/timm/maxvit_xlarge_tf_512.in21k_ft_in1k">link</a></td>
</tr>
<tr>
<td align="left">maxvit_xlarge_tf_384.in21k_ft_in1k</td>
<td align="right">88.3</td>
<td align="right">475.3</td>
<td align="right">292.8</td>
<td align="right">668.8</td>
<td align="left"><a href="https://huggingface.co/timm/maxvit_xlarge_tf_384.in21k_ft_in1k">link</a></td>
</tr>
<tr>
<td align="left">maxvit_base_tf_512.in21k_ft_in1k</td>
<td align="right">88.2</td>
<td align="right">119.9</td>
<td align="right">138</td>
<td align="right">704</td>
<td align="left"><a href="https://huggingface.co/timm/maxvit_base_tf_512.in21k_ft_in1k">link</a></td>
</tr>
<tr>
<td align="left">maxvit_large_tf_512.in21k_ft_in1k</td>
<td align="right">88</td>
<td align="right">212.3</td>
<td align="right">244.8</td>
<td align="right">942.2</td>
<td align="left"><a href="https://huggingface.co/timm/maxvit_large_tf_512.in21k_ft_in1k">link</a></td>
</tr>
<tr>
<td align="left">maxvit_large_tf_384.in21k_ft_in1k</td>
<td align="right">88</td>
<td align="right">212</td>
<td align="right">132.6</td>
<td align="right">445.8</td>
<td align="left"><a href="https://huggingface.co/timm/maxvit_large_tf_384.in21k_ft_in1k">link</a></td>
</tr>
<tr>
<td align="left">maxvit_base_tf_384.in21k_ft_in1k</td>
<td align="right">87.9</td>
<td align="right">119.6</td>
<td align="right">73.8</td>
<td align="right">332.9</td>
<td align="left"><a href="https://huggingface.co/timm/maxvit_base_tf_384.in21k_ft_in1k">link</a></td>
</tr>
<tr>
<td align="left">maxvit_base_tf_512.in1k</td>
<td align="right">86.6</td>
<td align="right">119.9</td>
<td align="right">138</td>
<td align="right">704</td>
<td align="left"><a href="https://huggingface.co/timm/maxvit_base_tf_512.in1k">link</a></td>
</tr>
<tr>
<td align="left">maxvit_large_tf_512.in1k</td>
<td align="right">86.5</td>
<td align="right">212.3</td>
<td align="right">244.8</td>
<td align="right">942.2</td>
<td align="left"><a href="https://huggingface.co/timm/maxvit_large_tf_512.in1k">link</a></td>
</tr>
<tr>
<td align="left">maxvit_base_tf_384.in1k</td>
<td align="right">86.3</td>
<td align="right">119.6</td>
<td align="right">73.8</td>
<td align="right">332.9</td>
<td align="left"><a href="https://huggingface.co/timm/maxvit_base_tf_384.in1k">link</a></td>
</tr>
<tr>
<td align="left">maxvit_large_tf_384.in1k</td>
<td align="right">86.2</td>
<td align="right">212</td>
<td align="right">132.6</td>
<td align="right">445.8</td>
<td align="left"><a href="https://huggingface.co/timm/maxvit_large_tf_384.in1k">link</a></td>
</tr>
<tr>
<td align="left">maxvit_small_tf_512.in1k</td>
<td align="right">86.1</td>
<td align="right">69.1</td>
<td align="right">67.3</td>
<td align="right">383.8</td>
<td align="left"><a href="https://huggingface.co/timm/maxvit_small_tf_512.in1k">link</a></td>
</tr>
<tr>
<td align="left">maxvit_tiny_tf_512.in1k</td>
<td align="right">85.7</td>
<td align="right">31</td>
<td align="right">33.5</td>
<td align="right">257.6</td>
<td align="left"><a href="https://huggingface.co/timm/maxvit_tiny_tf_512.in1k">link</a></td>
</tr>
<tr>
<td align="left">maxvit_small_tf_384.in1k</td>
<td align="right">85.5</td>
<td align="right">69</td>
<td align="right">35.9</td>
<td align="right">183.6</td>
<td align="left"><a href="https://huggingface.co/timm/maxvit_small_tf_384.in1k">link</a></td>
</tr>
<tr>
<td align="left">maxvit_tiny_tf_384.in1k</td>
<td align="right">85.1</td>
<td align="right">31</td>
<td align="right">17.5</td>
<td align="right">123.4</td>
<td align="left"><a href="https://huggingface.co/timm/maxvit_tiny_tf_384.in1k">link</a></td>
</tr>
<tr>
<td align="left">maxvit_large_tf_224.in1k</td>
<td align="right">84.9</td>
<td align="right">211.8</td>
<td align="right">43.7</td>
<td align="right">127.4</td>
<td align="left"><a href="https://huggingface.co/timm/maxvit_large_tf_224.in1k">link</a></td>
</tr>
<tr>
<td align="left">maxvit_base_tf_224.in1k</td>
<td align="right">84.9</td>
<td align="right">119.5</td>
<td align="right">24</td>
<td align="right">95</td>
<td align="left"><a href="https://huggingface.co/timm/maxvit_base_tf_224.in1k">link</a></td>
</tr>
<tr>
<td align="left">maxvit_small_tf_224.in1k</td>
<td align="right">84.4</td>
<td align="right">68.9</td>
<td align="right">11.7</td>
<td align="right">53.2</td>
<td align="left"><a href="https://huggingface.co/timm/maxvit_small_tf_224.in1k">link</a></td>
</tr>
<tr>
<td align="left">maxvit_tiny_tf_224.in1k</td>
<td align="right">83.4</td>
<td align="right">30.9</td>
<td align="right">5.6</td>
<td align="right">35.8</td>
<td align="left"><a href="https://huggingface.co/timm/maxvit_tiny_tf_224.in1k">link</a></td>
</tr>
</tbody>
</table>
<h3 id="oct-15-2022">Oct 15, 2022</h3>
<ul>
<li>Train and validation script enhancements</li>
<li>Non-GPU (ie CPU) device support</li>
<li>SLURM compatibility for train script</li>
<li>HF datasets support (via ReaderHfds)</li>
<li>TFDS/WDS dataloading improvements (sample padding/wrap for distributed use fixed wrt sample count estimate)</li>
<li>in_chans !=3 support for scripts / loader</li>
<li>Adan optimizer</li>
<li>Can enable per-step LR scheduling via args</li>
<li>Dataset 'parsers' renamed to 'readers', more descriptive of purpose</li>
<li>AMP args changed, APEX via <code>--amp-impl apex</code>, bfloat16 supportedf via <code>--amp-dtype bfloat16</code></li>
<li>main branch switched to 0.7.x version, 0.6x forked for stable release of weight only adds</li>
<li>master -&gt; main branch rename</li>
</ul>
<h3 id="oct-10-2022">Oct 10, 2022</h3>
<ul>
<li>More weights in <code>maxxvit</code> series, incl first ConvNeXt block based <code>coatnext</code> and <code>maxxvit</code> experiments:<ul>
<li><code>coatnext_nano_rw_224</code> - 82.0 @ 224 (G) -- (uses ConvNeXt conv block, no BatchNorm)</li>
<li><code>maxxvit_rmlp_nano_rw_256</code> - 83.0 @ 256, 83.7 @ 320  (G) (uses ConvNeXt conv block, no BN)</li>
<li><code>maxvit_rmlp_small_rw_224</code> - 84.5 @ 224, 85.1 @ 320 (G)</li>
<li><code>maxxvit_rmlp_small_rw_256</code> - 84.6 @ 256, 84.9 @ 288 (G) -- could be trained better, hparams need tuning (uses ConvNeXt block, no BN)</li>
<li><code>coatnet_rmlp_2_rw_224</code> - 84.6 @ 224, 85 @ 320  (T)</li>
<li>NOTE: official MaxVit weights (in1k) have been released at <a href="https://github.com/google-research/maxvit">https://github.com/google-research/maxvit</a> -- some extra work is needed to port and adapt since my impl was created independently of theirs and has a few small differences + the whole TF same padding fun.</li>
</ul>
</li>
</ul>
<h3 id="sept-23-2022">Sept 23, 2022</h3>
<ul>
<li>LAION-2B CLIP image towers supported as pretrained backbones for fine-tune or features (no classifier)<ul>
<li>vit_base_patch32_224_clip_laion2b</li>
<li>vit_large_patch14_224_clip_laion2b</li>
<li>vit_huge_patch14_224_clip_laion2b</li>
<li>vit_giant_patch14_224_clip_laion2b</li>
</ul>
</li>
</ul>
<h3 id="sept-7-2022">Sept 7, 2022</h3>
<ul>
<li>Hugging Face <a href="https://huggingface.co/docs/hub/timm"><code>timm</code> docs</a> home now exists, look for more here in the future</li>
<li>Add BEiT-v2 weights for base and large 224x224 models from <a href="https://github.com/microsoft/unilm/tree/master/beit2">https://github.com/microsoft/unilm/tree/master/beit2</a></li>
<li>Add more weights in <code>maxxvit</code> series incl a <code>pico</code> (7.5M params, 1.9 GMACs), two <code>tiny</code> variants:<ul>
<li><code>maxvit_rmlp_pico_rw_256</code> - 80.5 @ 256, 81.3 @ 320  (T)</li>
<li><code>maxvit_tiny_rw_224</code> - 83.5 @ 224 (G)</li>
<li><code>maxvit_rmlp_tiny_rw_256</code> - 84.2 @ 256, 84.8 @ 320 (T)</li>
</ul>
</li>
</ul>
<h3 id="aug-29-2022">Aug 29, 2022</h3>
<ul>
<li>MaxVit window size scales with img_size by default. Add new RelPosMlp MaxViT weight that leverages this:<ul>
<li><code>maxvit_rmlp_nano_rw_256</code> - 83.0 @ 256, 83.6 @ 320  (T)</li>
</ul>
</li>
</ul>
<h3 id="aug-26-2022">Aug 26, 2022</h3>
<ul>
<li>CoAtNet (<a href="https://arxiv.org/abs/2106.04803">https://arxiv.org/abs/2106.04803</a>) and MaxVit (<a href="https://arxiv.org/abs/2204.01697">https://arxiv.org/abs/2204.01697</a>) <code>timm</code> original models<ul>
<li>both found in <a href="https://github.com/rwightman/pytorch-image-models/blob/master/timm/models/maxxvit.py"><code>maxxvit.py</code></a> model def, contains numerous experiments outside scope of original papers</li>
<li>an unfinished Tensorflow version from MaxVit authors can be found <a href="https://github.com/google-research/maxvit">https://github.com/google-research/maxvit</a></li>
</ul>
</li>
<li>Initial CoAtNet and MaxVit timm pretrained weights (working on more):<ul>
<li><code>coatnet_nano_rw_224</code> - 81.7 @ 224  (T)</li>
<li><code>coatnet_rmlp_nano_rw_224</code> - 82.0 @ 224, 82.8 @ 320 (T)</li>
<li><code>coatnet_0_rw_224</code> - 82.4  (T)  -- NOTE timm '0' coatnets have 2 more 3<sup>rd</sup> stage blocks</li>
<li><code>coatnet_bn_0_rw_224</code> - 82.4  (T)</li>
<li><code>maxvit_nano_rw_256</code> - 82.9 @ 256  (T)</li>
<li><code>coatnet_rmlp_1_rw_224</code> - 83.4 @ 224, 84 @ 320  (T)</li>
<li><code>coatnet_1_rw_224</code> - 83.6 @ 224 (G) </li>
<li>(T) = TPU trained with <code>bits_and_tpu</code> branch training code, (G) = GPU trained</li>
</ul>
</li>
<li>GCVit (weights adapted from <a href="https://github.com/NVlabs/GCVit">https://github.com/NVlabs/GCVit</a>, code 100% <code>timm</code> re-write for license purposes)</li>
<li>MViT-V2 (multi-scale vit, adapted from <a href="https://github.com/facebookresearch/mvit">https://github.com/facebookresearch/mvit</a>)</li>
<li>EfficientFormer (adapted from <a href="https://github.com/snap-research/EfficientFormer">https://github.com/snap-research/EfficientFormer</a>)</li>
<li>PyramidVisionTransformer-V2 (adapted from <a href="https://github.com/whai362/PVT">https://github.com/whai362/PVT</a>)</li>
<li>'Fast Norm' support for LayerNorm and GroupNorm that avoids float32 upcast w/ AMP (uses APEX LN if available for further boost)</li>
</ul>
<h3 id="aug-15-2022">Aug 15, 2022</h3>
<ul>
<li>ConvNeXt atto weights added<ul>
<li><code>convnext_atto</code> - 75.7 @ 224, 77.0 @ 288</li>
<li><code>convnext_atto_ols</code> - 75.9  @ 224, 77.2 @ 288</li>
</ul>
</li>
</ul>
<h3 id="aug-5-2022">Aug 5, 2022</h3>
<ul>
<li>More custom ConvNeXt smaller model defs with weights <ul>
<li><code>convnext_femto</code> - 77.5 @ 224, 78.7 @ 288</li>
<li><code>convnext_femto_ols</code> - 77.9  @ 224, 78.9 @ 288</li>
<li><code>convnext_pico</code> - 79.5 @ 224, 80.4 @ 288</li>
<li><code>convnext_pico_ols</code> - 79.5 @ 224, 80.5 @ 288</li>
<li><code>convnext_nano_ols</code> - 80.9 @ 224, 81.6 @ 288</li>
</ul>
</li>
<li>Updated EdgeNeXt to improve ONNX export, add new base variant and weights from original (<a href="https://github.com/mmaaz60/EdgeNeXt">https://github.com/mmaaz60/EdgeNeXt</a>)</li>
</ul>
<h3 id="july-28-2022">July 28, 2022</h3>
<ul>
<li>Add freshly minted DeiT-III Medium (width=512, depth=12, num_heads=8) model weights. Thanks <a href="https://github.com/TouvronHugo">Hugo Touvron</a>!</li>
</ul>
<h3 id="july-27-2022">July 27, 2022</h3>
<ul>
<li>All runtime benchmark and validation result csv files are up-to-date!</li>
<li>A few more weights &amp; model defs added:<ul>
<li><code>darknetaa53</code> -  79.8 @ 256, 80.5 @ 288</li>
<li><code>convnext_nano</code> - 80.8 @ 224, 81.5 @ 288</li>
<li><code>cs3sedarknet_l</code> - 81.2 @ 256, 81.8 @ 288</li>
<li><code>cs3darknet_x</code> - 81.8 @ 256, 82.2 @ 288</li>
<li><code>cs3sedarknet_x</code> - 82.2 @ 256, 82.7 @ 288</li>
<li><code>cs3edgenet_x</code> - 82.2 @ 256, 82.7 @ 288</li>
<li><code>cs3se_edgenet_x</code> - 82.8 @ 256, 83.5 @ 320</li>
</ul>
</li>
<li><code>cs3*</code> weights above all trained on TPU w/ <code>bits_and_tpu</code> branch. Thanks to TRC program!</li>
<li>Add output_stride=8 and 16 support to ConvNeXt (dilation)</li>
<li>deit3 models not being able to resize pos_emb fixed</li>
<li>Version 0.6.7 PyPi release (/w above bug fixes and new weighs since 0.6.5)</li>
</ul>
<h3 id="july-8-2022">July 8, 2022</h3>
<p>More models, more fixes
* Official research models (w/ weights) added:
  * EdgeNeXt from (<a href="https://github.com/mmaaz60/EdgeNeXt">https://github.com/mmaaz60/EdgeNeXt</a>)
  * MobileViT-V2 from (<a href="https://github.com/apple/ml-cvnets">https://github.com/apple/ml-cvnets</a>)
  * DeiT III (Revenge of the ViT) from (<a href="https://github.com/facebookresearch/deit">https://github.com/facebookresearch/deit</a>)
* My own models:
  * Small <code>ResNet</code> defs added by request with 1 block repeats for both basic and bottleneck (resnet10 and resnet14)
  * <code>CspNet</code> refactored with dataclass config, simplified CrossStage3 (<code>cs3</code>) option. These are closer to YOLO-v5+ backbone defs.
  * More relative position vit fiddling. Two <code>srelpos</code> (shared relative position) models trained, and a medium w/ class token.
  * Add an alternate downsample mode to EdgeNeXt and train a <code>small</code> model. Better than original small, but not their new USI trained weights.
* My own model weight results (all ImageNet-1k training)
  * <code>resnet10t</code> - 66.5 @ 176, 68.3 @ 224
  * <code>resnet14t</code> - 71.3 @ 176, 72.3 @ 224
  * <code>resnetaa50</code> - 80.6 @ 224 , 81.6 @ 288
  * <code>darknet53</code> -  80.0 @ 256, 80.5 @ 288
  * <code>cs3darknet_m</code> - 77.0 @ 256, 77.6 @ 288
  * <code>cs3darknet_focus_m</code> - 76.7 @ 256, 77.3 @ 288
  * <code>cs3darknet_l</code> - 80.4 @ 256, 80.9 @ 288
  * <code>cs3darknet_focus_l</code> - 80.3 @ 256, 80.9 @ 288
  * <code>vit_srelpos_small_patch16_224</code> - 81.1 @ 224, 82.1 @ 320
  * <code>vit_srelpos_medium_patch16_224</code> - 82.3 @ 224, 83.1 @ 320
  * <code>vit_relpos_small_patch16_cls_224</code> - 82.6 @ 224, 83.6 @ 320
  * <code>edgnext_small_rw</code> - 79.6 @ 224, 80.4 @ 320
* <code>cs3</code>, <code>darknet</code>, and <code>vit_*relpos</code> weights above all trained on TPU thanks to TRC program! Rest trained on overheating GPUs.
* Hugging Face Hub support fixes verified, demo notebook TBA
* Pretrained weights / configs can be loaded externally (ie from local disk) w/ support for head adaptation.
* Add support to change image extensions scanned by <code>timm</code> datasets/parsers. See (<a href="https://github.com/rwightman/pytorch-image-models/pull/1274#issuecomment-1178303103">https://github.com/rwightman/pytorch-image-models/pull/1274#issuecomment-1178303103</a>)
* Default ConvNeXt LayerNorm impl to use <code>F.layer_norm(x.permute(0, 2, 3, 1), ...).permute(0, 3, 1, 2)</code> via <code>LayerNorm2d</code> in all cases. 
  * a bit slower than previous custom impl on some hardware (ie Ampere w/ CL), but overall fewer regressions across wider HW / PyTorch version ranges. 
  * previous impl exists as <code>LayerNormExp2d</code> in <code>models/layers/norm.py</code>
* Numerous bug fixes
* Currently testing for imminent PyPi 0.6.x release
* LeViT pretraining of larger models still a WIP, they don't train well / easily without distillation. Time to add distill support (finally)?
* ImageNet-22k weight training + finetune ongoing, work on multi-weight support (slowly) chugging along (there are a LOT of weights, sigh) ...</p>
<h3 id="may-13-2022">May 13, 2022</h3>
<ul>
<li>Official Swin-V2 models and weights added from (<a href="https://github.com/microsoft/Swin-Transformer">https://github.com/microsoft/Swin-Transformer</a>). Cleaned up to support torchscript.</li>
<li>Some refactoring for existing <code>timm</code> Swin-V2-CR impl, will likely do a bit more to bring parts closer to official and decide whether to merge some aspects.</li>
<li>More Vision Transformer relative position / residual post-norm experiments (all trained on TPU thanks to TRC program)<ul>
<li><code>vit_relpos_small_patch16_224</code> - 81.5 @ 224, 82.5 @ 320 -- rel pos, layer scale, no class token, avg pool</li>
<li><code>vit_relpos_medium_patch16_rpn_224</code> - 82.3 @ 224, 83.1 @ 320 -- rel pos + res-post-norm, no class token, avg pool</li>
<li><code>vit_relpos_medium_patch16_224</code> - 82.5 @ 224, 83.3 @ 320 -- rel pos, layer scale, no class token, avg pool</li>
<li><code>vit_relpos_base_patch16_gapcls_224</code> - 82.8 @ 224, 83.9 @ 320 -- rel pos, layer scale, class token, avg pool (by mistake)</li>
</ul>
</li>
<li>Bring 512 dim, 8-head 'medium' ViT model variant back to life (after using in a pre DeiT 'small' model for first ViT impl back in 2020)</li>
<li>Add ViT relative position support for switching btw existing impl and some additions in official Swin-V2 impl for future trials</li>
<li>Sequencer2D impl (<a href="https://arxiv.org/abs/2205.01972">https://arxiv.org/abs/2205.01972</a>), added via PR from author (<a href="https://github.com/okojoalg">https://github.com/okojoalg</a>)</li>
</ul>
<h3 id="may-2-2022">May 2, 2022</h3>
<ul>
<li>Vision Transformer experiments adding Relative Position (Swin-V2 log-coord) (<code>vision_transformer_relpos.py</code>) and Residual Post-Norm branches (from Swin-V2) (<code>vision_transformer*.py</code>)<ul>
<li><code>vit_relpos_base_patch32_plus_rpn_256</code> - 79.5 @ 256, 80.6 @ 320 -- rel pos + extended width + res-post-norm, no class token, avg pool</li>
<li><code>vit_relpos_base_patch16_224</code> - 82.5 @ 224, 83.6 @ 320 -- rel pos, layer scale, no class token, avg pool</li>
<li><code>vit_base_patch16_rpn_224</code> - 82.3 @ 224 -- rel pos + res-post-norm, no class token, avg pool</li>
</ul>
</li>
<li>Vision Transformer refactor to remove representation layer that was only used in initial vit and rarely used since with newer pretrain (ie <code>How to Train Your ViT</code>)</li>
<li><code>vit_*</code> models support removal of class token, use of global average pool, use of fc_norm (ala beit, mae).</li>
</ul>
<h3 id="april-22-2022">April 22, 2022</h3>
<ul>
<li><code>timm</code> models are now officially supported in <a href="https://www.fast.ai/">fast.ai</a>! Just in time for the new Practical Deep Learning course. <code>timmdocs</code> documentation link updated to <a href="http://timm.fast.ai/">timm.fast.ai</a>.</li>
<li>Two more model weights added in the TPU trained <a href="https://github.com/rwightman/pytorch-image-models/releases/tag/v0.1-tpu-weights">series</a>. Some In22k pretrain still in progress.<ul>
<li><code>seresnext101d_32x8d</code> - 83.69 @ 224, 84.35 @ 288</li>
<li><code>seresnextaa101d_32x8d</code> (anti-aliased w/ AvgPool2d) - 83.85 @ 224, 84.57 @ 288</li>
</ul>
</li>
</ul>
<h3 id="march-23-2022">March 23, 2022</h3>
<ul>
<li>Add <code>ParallelBlock</code> and <code>LayerScale</code> option to base vit models to support model configs in <a href="https://arxiv.org/abs/2203.09795">Three things everyone should know about ViT</a></li>
<li><code>convnext_tiny_hnf</code> (head norm first) weights trained with (close to) A2 recipe, 82.2% top-1, could do better with more epochs.</li>
</ul>
<h3 id="march-21-2022">March 21, 2022</h3>
<ul>
<li>Merge <code>norm_norm_norm</code>. <strong>IMPORTANT</strong> this update for a coming 0.6.x release will likely de-stabilize the master branch for a while. Branch <a href="https://github.com/rwightman/pytorch-image-models/tree/0.5.x"><code>0.5.x</code></a> or a previous 0.5.x release can be used if stability is required.</li>
<li>Significant weights update (all TPU trained) as described in this <a href="https://github.com/rwightman/pytorch-image-models/releases/tag/v0.1-tpu-weights">release</a><ul>
<li><code>regnety_040</code> - 82.3 @ 224, 82.96 @ 288</li>
<li><code>regnety_064</code> - 83.0 @ 224, 83.65 @ 288</li>
<li><code>regnety_080</code> - 83.17 @ 224, 83.86 @ 288</li>
<li><code>regnetv_040</code> - 82.44 @ 224, 83.18 @ 288   (timm pre-act)</li>
<li><code>regnetv_064</code> - 83.1 @ 224, 83.71 @ 288   (timm pre-act)</li>
<li><code>regnetz_040</code> - 83.67 @ 256, 84.25 @ 320</li>
<li><code>regnetz_040h</code> - 83.77 @ 256, 84.5 @ 320 (w/ extra fc in head)</li>
<li><code>resnetv2_50d_gn</code> - 80.8 @ 224, 81.96 @ 288 (pre-act GroupNorm)</li>
<li><code>resnetv2_50d_evos</code> 80.77 @ 224, 82.04 @ 288 (pre-act EvoNormS)</li>
<li><code>regnetz_c16_evos</code>  - 81.9 @ 256, 82.64 @ 320 (EvoNormS)</li>
<li><code>regnetz_d8_evos</code>  - 83.42 @ 256, 84.04 @ 320 (EvoNormS)</li>
<li><code>xception41p</code> - 82 @ 299   (timm pre-act)</li>
<li><code>xception65</code> -  83.17 @ 299</li>
<li><code>xception65p</code> -  83.14 @ 299   (timm pre-act)</li>
<li><code>resnext101_64x4d</code> - 82.46 @ 224, 83.16 @ 288</li>
<li><code>seresnext101_32x8d</code> - 83.57 @ 224, 84.270 @ 288</li>
<li><code>resnetrs200</code> - 83.85 @ 256, 84.44 @ 320</li>
</ul>
</li>
<li>HuggingFace hub support fixed w/ initial groundwork for allowing alternative 'config sources' for pretrained model definitions and weights (generic local file / remote url support soon)</li>
<li>SwinTransformer-V2 implementation added. Submitted by <a href="https://github.com/ChristophReich1996">Christoph Reich</a>. Training experiments and model changes by myself are ongoing so expect compat breaks.</li>
<li>Swin-S3 (AutoFormerV2) models / weights added from <a href="https://github.com/microsoft/Cream/tree/main/AutoFormerV2">https://github.com/microsoft/Cream/tree/main/AutoFormerV2</a></li>
<li>MobileViT models w/ weights adapted from <a href="https://github.com/apple/ml-cvnets">https://github.com/apple/ml-cvnets</a></li>
<li>PoolFormer models w/ weights adapted from <a href="https://github.com/sail-sg/poolformer">https://github.com/sail-sg/poolformer</a></li>
<li>VOLO models w/ weights adapted from <a href="https://github.com/sail-sg/volo">https://github.com/sail-sg/volo</a></li>
<li>Significant work experimenting with non-BatchNorm norm layers such as EvoNorm, FilterResponseNorm, GroupNorm, etc</li>
<li>Enhance support for alternate norm + act ('NormAct') layers added to a number of models, esp EfficientNet/MobileNetV3, RegNet, and aligned Xception</li>
<li>Grouped conv support added to EfficientNet family</li>
<li>Add 'group matching' API to all models to allow grouping model parameters for application of 'layer-wise' LR decay, lr scale added to LR scheduler</li>
<li>Gradient checkpointing support added to many models</li>
<li><code>forward_head(x, pre_logits=False)</code> fn added to all models to allow separate calls of <code>forward_features</code> + <code>forward_head</code></li>
<li>All vision transformer and vision MLP models update to return non-pooled / non-token selected features from <code>foward_features</code>, for consistency with CNN models, token selection or pooling now applied in <code>forward_head</code></li>
</ul>
<h3 id="feb-2-2022">Feb 2, 2022</h3>
<ul>
<li><a href="https://github.com/Chris-hughes10">Chris Hughes</a> posted an exhaustive run through of <code>timm</code> on his blog yesterday. Well worth a read. <a href="https://towardsdatascience.com/getting-started-with-pytorch-image-models-timm-a-practitioners-guide-4e77b4bf9055">Getting Started with PyTorch Image Models (timm): A Practitionerâ€™s Guide</a></li>
<li>I'm currently prepping to merge the <code>norm_norm_norm</code> branch back to master (ver 0.6.x) in next week or so.<ul>
<li>The changes are more extensive than usual and may destabilize and break some model API use (aiming for full backwards compat). So, beware <code>pip install git+https://github.com/rwightman/pytorch-image-models</code> installs!</li>
<li><code>0.5.x</code> releases and a <code>0.5.x</code> branch will remain stable with a cherry pick or two until dust clears. Recommend sticking to pypi install for a bit if you want stable.</li>
</ul>
</li>
</ul>
<h3 id="jan-14-2022">Jan 14, 2022</h3>
<ul>
<li>Version 0.5.4 w/ release to be pushed to pypi. It's been a while since last pypi update and riskier changes will be merged to main branch soon....</li>
<li>Add ConvNeXT models /w weights from official impl (<a href="https://github.com/facebookresearch/ConvNeXt">https://github.com/facebookresearch/ConvNeXt</a>), a few perf tweaks, compatible with timm features</li>
<li>Tried training a few small (~1.8-3M param) / mobile optimized models, a few are good so far, more on the way...<ul>
<li><code>mnasnet_small</code> - 65.6 top-1</li>
<li><code>mobilenetv2_050</code> - 65.9</li>
<li><code>lcnet_100/075/050</code> - 72.1 / 68.8 / 63.1</li>
<li><code>semnasnet_075</code> - 73</li>
<li><code>fbnetv3_b/d/g</code> - 79.1 / 79.7 / 82.0</li>
</ul>
</li>
<li>TinyNet models added by <a href="https://github.com/rsomani95">rsomani95</a></li>
<li>LCNet added via MobileNetV3 architecture</li>
</ul>





                
              </article>
            </div>
          
          
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    <script id="__config" type="application/json">{"base": "..", "features": [], "search": "../assets/javascripts/workers/search.12658920.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../assets/javascripts/bundle.5cf534bf.min.js"></script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML"></script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/tablesort/5.2.1/tablesort.min.js"></script>
      
        <script src="../javascripts/tables.js"></script>
      
    
  </body>
</html>